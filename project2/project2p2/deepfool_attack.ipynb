{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"deepfool_attack.ipynb","provenance":[],"mount_file_id":"1dFild9Kfp3pF2flfukYoKy1pLQyQzfEj","authorship_tag":"ABX9TyPNUJuMNQcBFWrwoPiDQ53V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0_VCw2W44dN","executionInfo":{"status":"ok","timestamp":1651972161157,"user_tz":240,"elapsed":153,"user":{"displayName":"Qihua Gong","userId":"03267308857545272138"}},"outputId":"d5a5f219-1064-4970-eefa-5ea70b44328c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"-pMAFbmeNnWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior() \n","from attacks import deepfool\n","\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","\n","img_size = 28\n","img_chan = 1\n","n_classes = 10\n","\n","\n","print('\\nLoading MNIST')\n","\n","dataset = tf.keras.datasets.mnist\n","(X_train, y_train), (X_test, y_test) = dataset.load_data()\n","X_train = np.reshape(X_train, [-1, img_size, img_size, img_chan])\n","X_train = X_train.astype(np.float32) / 255\n","X_test = np.reshape(X_test, [-1, img_size, img_size, img_chan])\n","X_test = X_test.astype(np.float32) / 255\n","\n","Categorical = tf.keras.utils.to_categorical\n","y_train = Categorical(y_train)\n","y_test = Categorical(y_test)\n","\n","ind = np.random.permutation(X_train.shape[0])\n","X_train, y_train = X_train[ind], y_train[ind]\n","\n","SPLIT = 0.1\n","n = int(X_train.shape[0] * (1-SPLIT))\n","X_valid = X_train[n:]\n","X_train = X_train[:n]\n","y_valid = y_train[n:]\n","y_train = y_train[:n]\n","\n","\n","\n","def model(x, logits=False, training=False):\n","    with tf.variable_scope('conv0'):\n","        z = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n","                             padding='same', activation=tf.nn.relu)\n","        z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n","\n","    with tf.variable_scope('conv1'):\n","        z = tf.layers.conv2d(z, filters=64, kernel_size=[3, 3],\n","                             padding='same', activation=tf.nn.relu)\n","        z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n","\n","    with tf.variable_scope('flatten'):\n","        shape = z.get_shape().as_list()\n","        z = tf.reshape(z, [-1, np.prod(shape[1:])])\n","\n","    with tf.variable_scope('mlp'):\n","        z = tf.layers.dense(z, units=128, activation=tf.nn.relu)\n","        z = tf.layers.dropout(z, rate=0.25, training=training)\n","\n","    LOGITS = tf.layers.dense(z, units=10, name='logits')\n","    y = tf.nn.softmax(LOGITS, name='ybar')\n","\n","    if logits:\n","        return y, LOGITS\n","    return y\n","\n","\n","class Dummy:\n","    pass\n","\n","\n","res = Dummy()\n","\n","\n","with tf.variable_scope('model'):\n","    res.x = tf.placeholder(tf.float32, (None, img_size, img_size, img_chan),\n","                           name='x')\n","    res.y = tf.placeholder(tf.float32, (None, n_classes), name='y')\n","    res.training = tf.placeholder_with_default(False, (), name='mode')\n","\n","    res.ybar, logits = model(res.x, logits=True, training=res.training)\n","\n","    with tf.variable_scope('acc'):\n","        count = tf.equal(tf.argmax(res.y, axis=1), tf.argmax(res.ybar, axis=1))\n","        res.acc = tf.reduce_mean(tf.cast(count, tf.float32), name='acc')\n","\n","    with tf.variable_scope('loss'):\n","        xent = tf.nn.softmax_cross_entropy_with_logits(labels=res.y,\n","                                                       logits=logits)\n","        res.loss = tf.reduce_mean(xent, name='loss')\n","\n","    with tf.variable_scope('train_op'):\n","        optimizer = tf.train.AdamOptimizer()\n","        res.train_op = optimizer.minimize(res.loss)\n","\n","    res.saver = tf.train.Saver()\n","\n","with tf.variable_scope('model', reuse=True):\n","    res.adv_epochs = tf.placeholder(tf.int32, (), name='adv_epochs')\n","    res.xadv = deepfool(model, res.x, epochs=res.adv_epochs)\n","\n","\n","graph = tf.InteractiveSession()\n","graph.run(tf.global_variables_initializer())\n","graph.run(tf.local_variables_initializer())\n","\n","\n","def evaluate(graph, res, X_data, y_data, batch_size=128):\n","\n","    print('\\nEvaluating')\n","\n","    datasample = X_data.shape[0]\n","    databatch = int((datasample+batch_size-1) / batch_size)\n","    loss, acc = 0, 0\n","\n","    for batch in range(databatch):\n","        print(' batch {0}/{1}'.format(batch + 1, databatch), end='\\r')\n","        start = batch * batch_size\n","        end = min(datasample, start + batch_size)\n","        cnt = end - start\n","        batch_loss, batch_acc = graph.run(\n","            [res.loss, res.acc],\n","            feed_dict={res.x: X_data[start:end],\n","                       res.y: y_data[start:end]})\n","        loss += batch_loss * cnt\n","        acc += batch_acc * cnt\n","    loss /= datasample\n","    acc /= datasample\n","\n","    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n","    return loss, acc\n","\n","\n","def train(graph, res, X_data, y_data, X_valid=None, y_valid=None, epochs=1,\n","          load=False, shuffle=True, batch_size=128, name='model'):\n","\n","    if load:\n","        if not hasattr(res, 'saver'):\n","            return print('\\nError: cannot find saver op')\n","        print('\\nLoading saved model')\n","        return res.saver.restore(graph, 'model/{}'.format(name))\n","\n","    print('\\nTrain model')\n","    datasample = X_data.shape[0]\n","    databatch = int((datasample+batch_size-1) / batch_size)\n","    for epoch in range(epochs):\n","        print('\\nEpoch {0}/{1}'.format(epoch + 1, epochs))\n","\n","        if shuffle:\n","            ind = np.arange(datasample)\n","            np.random.shuffle(ind)\n","            X_data = X_data[ind]\n","            y_data = y_data[ind]\n","\n","        for batch in range(databatch):\n","            print(' batch {0}/{1}'.format(batch + 1, databatch), end='\\r')\n","            start = batch * batch_size\n","            end = min(datasample, start + batch_size)\n","            graph.run(res.train_op, feed_dict={res.x: X_data[start:end],\n","                                              res.y: y_data[start:end],\n","                                              res.training: True})\n","        if X_valid is not None:\n","            evaluate(graph, res, X_valid, y_valid)\n","\n","    if hasattr(res, 'saver'):\n","        print('\\n Saving model')\n","        os.makedirs('model', exist_ok=True)\n","        res.saver.save(graph, 'model/{}'.format(name))\n","\n","\n","def predict(graph, res, X_data, batch_size=128):\n","\n","    print('\\nPredicting')\n","    n_classes = res.ybar.get_shape().as_list()[1]\n","\n","    datasample = X_data.shape[0]\n","    databatch = int((datasample+batch_size-1) / batch_size)\n","    yval = np.empty((datasample, n_classes))\n","\n","    for batch in range(databatch):\n","        print(' batch {0}/{1}'.format(batch + 1, databatch), end='\\r')\n","        start = batch * batch_size\n","        end = min(datasample, start + batch_size)\n","        y_batch = graph.run(res.ybar, feed_dict={res.x: X_data[start:end]})\n","        yval[start:end] = y_batch\n","    print()\n","    return yval\n","\n","\n","def make_deepfool(graph, res, X_data, epochs=1, eps=0.01, batch_size=128):\n","\n","    print('\\nMaking adversarials via DeepFool')\n","\n","    datasample = X_data.shape[0]\n","    databatch = int((datasample + batch_size - 1) / batch_size)\n","    X_adv = np.empty_like(X_data)\n","\n","    for batch in range(databatch):\n","        print(' batch {0}/{1}'.format(batch + 1, databatch), end='\\r')\n","        start = batch * batch_size\n","        end = min(datasample, start + batch_size)\n","        adv = graph.run(res.xadv, feed_dict={res.x: X_data[start:end],\n","                                            res.adv_epochs: epochs})\n","        X_adv[start:end] = adv\n","    print()\n","\n","    return X_adv\n","\n","\n","print('\\nTraining')\n","\n","train(graph, res, X_train, y_train, X_valid, y_valid, load=False, epochs=5,\n","      name='mnist')\n","\n","print('\\nEvaluating on clean data')\n","\n","evaluate(graph, res, X_test, y_test)\n","\n","print('\\nGenerating adversarial data')\n","\n","X_adv = make_deepfool(graph, res, X_test, epochs=3)\n","\n","print('\\nEvaluating on adversarial data')\n","\n","evaluate(graph, res, X_adv, y_test)\n","\n","\n","y1 = predict(graph, res, X_test)\n","y2 = predict(graph, res, X_adv)\n","\n","z0 = np.argmax(y_test, axis=1)\n","z1 = np.argmax(y1, axis=1)\n","z2 = np.argmax(y2, axis=1)\n","\n","print('\\nPlotting results')\n","fig = plt.figure(figsize=(10, 2.2))\n","gs = gridspec.GridSpec(2, 10, wspace=0.05, hspace=0.05)\n","\n","for i in range(10):\n","    ind, = np.where(np.all([z0 == i, z1 == i, z2 != i], axis=0))\n","    ind = np.random.choice(ind)\n","    xcur = [X_test[ind], X_adv[ind]]\n","    ycur = y2[ind]\n","    zcur = z2[ind]\n","\n","    for j in range(2):\n","        img = np.squeeze(xcur[j])\n","        ans = fig.add_subplot(gs[j, i])\n","        ans.imshow(img, cmap='gray', interpolation='none')\n","        ans.set_xticks([])\n","        ans.set_yticks([])\n","    ans.set_xlabel('{0} ({1:.2f})'.format(zcur, ycur[zcur]), fontsize=12)\n","\n","print('\\nSaving figure')\n","gs.tight_layout(fig)\n","os.makedirs('img', exist_ok=True)\n","plt.savefig('img/deepfool_mnist.png')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8lzaz_Wl449U","executionInfo":{"status":"ok","timestamp":1651972713932,"user_tz":240,"elapsed":551198,"user":{"displayName":"Qihua Gong","userId":"03267308857545272138"}},"outputId":"6b48c1a2-3e25-4160-a485-d71aafc968d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","\n","Loading MNIST\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:575: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/pooling.py:600: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:413: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  return layer.apply(inputs, training=training)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/attacks/deepfool.py:49: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.while_loop(c, b, vars, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n","  return f(*args, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n","  return f(*args, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  return f(*args, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n","  return f(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training\n","\n","Train model\n","\n","Epoch 1/5\n","\n","Evaluating\n"," loss: 0.0670 acc: 0.9797\n","\n","Epoch 2/5\n","\n","Evaluating\n"," loss: 0.0464 acc: 0.9862\n","\n","Epoch 3/5\n"," batch 422/422\n","Evaluating\n"," loss: 0.0412 acc: 0.9877\n","\n","Epoch 4/5\n"," batch 422/422\n","Evaluating\n"," loss: 0.0360 acc: 0.9890\n","\n","Epoch 5/5\n"," batch 422/422\n","Evaluating\n"," loss: 0.0346 acc: 0.9902\n","\n"," Saving model\n","\n","Evaluating on clean data\n","\n","Evaluating\n"," loss: 0.0300 acc: 0.9898\n","\n","Generating adversarial data\n","\n","Making adversarials via DeepFool\n","\n","\n","Evaluating on adversarial data\n","\n","Evaluating\n"," loss: 1.6812 acc: 0.1285\n","\n","Predicting\n"," batch 79/79\n","\n","Predicting\n"," batch 79/79\n","\n","Plotting results\n","\n","Saving figure\n"]}]}]}