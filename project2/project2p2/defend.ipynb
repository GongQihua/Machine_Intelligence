{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"defend.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4gvHhfnS4NQPs6yI/Xx40"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"waAitlL9BbNq","executionInfo":{"status":"ok","timestamp":1651977095423,"user_tz":240,"elapsed":457067,"user":{"displayName":"Qihua Gong","userId":"03267308857545272138"}},"outputId":"9df4fb55-62a2-4f1e-f1ba-e54615c900f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1875/1875 [==============================] - 17s 9ms/step - loss: 0.0195 - accuracy: 0.8645 - val_loss: 0.0069 - val_accuracy: 0.9547\n","Epoch 2/10\n","1875/1875 [==============================] - 15s 8ms/step - loss: 0.0094 - accuracy: 0.9395 - val_loss: 0.0051 - val_accuracy: 0.9665\n","Epoch 3/10\n","1875/1875 [==============================] - 15s 8ms/step - loss: 0.0075 - accuracy: 0.9516 - val_loss: 0.0043 - val_accuracy: 0.9711\n","Epoch 4/10\n","1875/1875 [==============================] - 15s 8ms/step - loss: 0.0065 - accuracy: 0.9587 - val_loss: 0.0041 - val_accuracy: 0.9734\n","Epoch 5/10\n","1875/1875 [==============================] - 15s 8ms/step - loss: 0.0059 - accuracy: 0.9622 - val_loss: 0.0037 - val_accuracy: 0.9768\n","Epoch 6/10\n","1875/1875 [==============================] - 15s 8ms/step - loss: 0.0053 - accuracy: 0.9653 - val_loss: 0.0038 - val_accuracy: 0.9762\n","Epoch 7/10\n","1875/1875 [==============================] - 15s 8ms/step - loss: 0.0050 - accuracy: 0.9683 - val_loss: 0.0040 - val_accuracy: 0.9739\n","Epoch 8/10\n","1875/1875 [==============================] - 16s 8ms/step - loss: 0.0046 - accuracy: 0.9712 - val_loss: 0.0034 - val_accuracy: 0.9788\n","Epoch 9/10\n","1875/1875 [==============================] - 16s 8ms/step - loss: 0.0043 - accuracy: 0.9730 - val_loss: 0.0034 - val_accuracy: 0.9773\n","Epoch 10/10\n","1875/1875 [==============================] - 15s 8ms/step - loss: 0.0042 - accuracy: 0.9737 - val_loss: 0.0032 - val_accuracy: 0.9795\n","accuracy on regular images: [0.0031986036337912083, 0.9794999957084656]\n","accuracy on adversarial images: [0.12948882579803467, 0.1889999955892563]\n","Epoch 1/10\n","625/625 [==============================] - 6s 9ms/step - loss: 0.0059 - accuracy: 0.9658 - val_loss: 0.0109 - val_accuracy: 0.9378\n","Epoch 2/10\n","625/625 [==============================] - 6s 9ms/step - loss: 0.0021 - accuracy: 0.9897 - val_loss: 0.0096 - val_accuracy: 0.9449\n","Epoch 3/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.0019 - accuracy: 0.9901 - val_loss: 0.0098 - val_accuracy: 0.9437\n","Epoch 4/10\n","625/625 [==============================] - 5s 8ms/step - loss: 0.0017 - accuracy: 0.9908 - val_loss: 0.0125 - val_accuracy: 0.9286\n","Epoch 5/10\n","625/625 [==============================] - 6s 9ms/step - loss: 5.0966e-05 - accuracy: 0.9998 - val_loss: 0.0108 - val_accuracy: 0.9381\n","Epoch 6/10\n","625/625 [==============================] - 6s 10ms/step - loss: 8.8130e-05 - accuracy: 0.9995 - val_loss: 0.0110 - val_accuracy: 0.9377\n","Epoch 7/10\n","625/625 [==============================] - 6s 10ms/step - loss: 1.3820e-04 - accuracy: 0.9991 - val_loss: 0.0124 - val_accuracy: 0.9320\n","Epoch 8/10\n","625/625 [==============================] - 5s 9ms/step - loss: 1.4693e-04 - accuracy: 0.9989 - val_loss: 0.0143 - val_accuracy: 0.9179\n","Epoch 9/10\n","625/625 [==============================] - 5s 8ms/step - loss: 5.0693e-05 - accuracy: 0.9998 - val_loss: 0.0138 - val_accuracy: 0.9228\n","Epoch 10/10\n","625/625 [==============================] - 5s 9ms/step - loss: 1.4993e-04 - accuracy: 0.9990 - val_loss: 0.0177 - val_accuracy: 0.9019\n","Defended accuracy on adversarial images: [4.527693917352879e-16, 1.0]\n","Defended accuracy on regular images: [0.017679112032055855, 0.9018999934196472]\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.callbacks import LambdaCallback\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","\n","img_rows, img_cols, channels = 28, 28, 1\n","num_classes = 10\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n","img_rows, img_cols, channels = 28, 28, 1\n","num_classes = 10\n","x_train = x_train / 255\n","x_test = x_test / 255\n","x_train = x_train.reshape((-1, img_rows, img_cols, channels))\n","x_test = x_test.reshape((-1, img_rows, img_cols, channels))\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","def create_model():\n","    model = Sequential()\n","    model.add(Conv2D(32, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu',\n","                     input_shape=(img_rows, img_cols, channels)))\n","    model.add(Conv2D(64, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(64, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.2))\n","    model.add(Flatten())\n","    model.add(Dense(32))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(32))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n","\n","    return model\n","\n","model = create_model()\n","model.fit(x_train, y_train,\n","          batch_size=32,\n","          epochs=10,\n","          validation_data=(x_test, y_test))\n","\n","print(\"accuracy on regular images:\", model.evaluate(x=x_test, y=y_test, verbose=0))\n","\n","def adversarial_pattern(image, label):\n","    image = tf.cast(image, tf.float32)\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.MSE(label, prediction)\n","    gradient = tape.gradient(loss, image)\n","    signed_grad = tf.sign(gradient)\n","    return signed_grad\n","\n","image = x_train[0]\n","image_label = y_train[0]\n","res = adversarial_pattern(image.reshape((1, img_rows, img_cols, channels)), image_label).numpy()\n","adversarial = image + res * 0.15\n","\n","def generate_adversarials(batch_size):\n","    while True:\n","        x = []\n","        y = []\n","        for batch in range(batch_size):\n","            N = random.randint(0, 100)\n","\n","            label = y_train[N]\n","            image = x_train[N]\n","\n","            res = adversarial_pattern(image.reshape((1, img_rows, img_cols, channels)), label).numpy()\n","\n","            epsilon = 0.15\n","            adversarial = image + res * epsilon\n","\n","            x.append(adversarial)\n","            y.append(y_train[N])\n","\n","        x = np.asarray(x).reshape((batch_size, img_rows, img_cols, channels))\n","        y = np.asarray(y)\n","\n","        yield x, y\n","\n","x_adv_test, y_adv_test = next(generate_adversarials(10000))\n","print(\"accuracy on adversarial images:\", model.evaluate(x=x_adv_test, y=y_adv_test, verbose=0))\n","\n","x_adv_train, y_adv_train = next(generate_adversarials(20000))\n","model.fit(x_adv_train, y_adv_train,\n","          batch_size=32,\n","          epochs=10,\n","          validation_data=(x_test, y_test))\n","\n","print(\"Defended accuracy on adversarial images:\", model.evaluate(x=x_adv_test, y=y_adv_test, verbose=0))\n","print(\"Defended accuracy on regular images:\", model.evaluate(x=x_test, y=y_test, verbose=0))"]}]}